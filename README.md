# Explainable AI

**Increase Trust and Confidence in your ML models through Explainable AI**

Business users may be reluctant to accept predictions made by ML models without understanding how the models made them. Lack of understanding leads to lower trust and acceptance. Data Scientists need mechanisms to understand why their models may be deviating from desired predictions and how they could make corrections. This talk will look at how to build transparency into ML pipelines and prediction, providing business users visibility to the process and outcomes.

This repository holds the presentation material and code that accompanies it.

## Libraries

1. lime
2. matplotlib
3. numpy
4. pandas
5. sklearn

## Setup

1. Create conda environment

  ```sh
  conda env create -f xai_env.yml
  ```

2. Activate conda environment

  ```sh
  conda activate xai
  ```

3. Add it to the jupyter notebook kernel

## Author

[Srinivas Anand](srinivas.anand@ilwllc.com)

## Changelog

8/16 - Added conda environment to go with these jupyter notebooks.
